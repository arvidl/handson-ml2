{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chapter 12 – Custom Models and Training with TensorFlow**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_This notebook contains all the sample code in chapter 12._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/ageron/handson-ml2/blob/master/12_custom_models_and_training_with_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://kaggle.com/kernels/welcome?src=https://github.com/ageron/handson-ml2/blob/master/12_custom_models_and_training_with_tensorflow.ipynb\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" /></a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures. We also check that Python 3.5 or later is installed (although Python 2.x may work, it is deprecated so we strongly recommend you use Python 3 instead), as well as Scikit-Learn ≥0.20 and TensorFlow ≥2.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-28 18:09:53.955771: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# TensorFlow ≥2.4 is required in this notebook\n",
    "# Earlier 2.x versions will mostly work the same, but with a few bugs\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.4\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"deep\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors and operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-28 18:09:58.155299: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-28 18:09:58.159031: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-28 18:09:58.159139: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-28 18:09:58.159849: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-28 18:09:58.160783: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-28 18:09:58.160893: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-28 18:09:58.160965: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-28 18:09:58.439544: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-28 18:09:58.439664: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-28 18:09:58.439737: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-28 18:09:58.439807: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14253 MB memory:  -> device: 0, name: NVIDIA RTX A5000 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant([[1., 2., 3.], [4., 5., 6.]]) # matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=42>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(42) # scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tf.constant([[1., 2., 3.], [4., 5., 6.]])\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[2., 3.],\n",
       "       [5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[2.],\n",
       "       [5.]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[..., 1, tf.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[11., 12., 13.],\n",
       "       [14., 15., 16.]], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[ 1.,  4.,  9.],\n",
       "       [16., 25., 36.]], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.square(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-28 18:10:03.173225: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[14., 32.],\n",
       "       [32., 77.]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t @ tf.transpose(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `keras.backend`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[11., 26.],\n",
       "       [14., 35.],\n",
       "       [19., 46.]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "K = keras.backend\n",
    "K.square(K.transpose(t)) + 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From/To NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([2., 4., 5.])>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([2., 4., 5.])\n",
    "tf.constant(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([ 4., 16., 25.])>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.square(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  4.,  9.],\n",
       "       [16., 25., 36.]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.square(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conflicting Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot compute AddV2 as input #1(zero-based) was expected to be a float tensor but is a int32 tensor [Op:AddV2]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tf.constant(2.0) + tf.constant(40)\n",
    "except tf.errors.InvalidArgumentError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot compute AddV2 as input #1(zero-based) was expected to be a float tensor but is a double tensor [Op:AddV2]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tf.constant(2.0) + tf.constant(40., dtype=tf.float64)\n",
    "except tf.errors.InvalidArgumentError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=42.0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = tf.constant(40., dtype=tf.float64)\n",
    "tf.constant(2.0) + tf.cast(t2, tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'hello world'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(b\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'caf\\xc3\\xa9'>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(\"café\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([ 99,  97, 102, 233], dtype=int32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = tf.constant([ord(c) for c in \"café\"])\n",
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=4>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = tf.strings.unicode_encode(u, \"UTF-8\")\n",
    "tf.strings.length(b, unit=\"UTF8_CHAR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([ 99,  97, 102, 233], dtype=int32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_decode(b, \"UTF-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = tf.constant([\"Café\", \"Coffee\", \"caffè\", \"咖啡\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([4, 6, 5, 2], dtype=int32)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.length(p, unit=\"UTF8_CHAR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[67, 97, 102, 233], [67, 111, 102, 102, 101, 101],\n",
       " [99, 97, 102, 102, 232], [21654, 21857]]>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = tf.strings.unicode_decode(p, \"UTF8\")\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[67, 97, 102, 233], [67, 111, 102, 102, 101, 101],\n",
      " [99, 97, 102, 102, 232], [21654, 21857]]>\n"
     ]
    }
   ],
   "source": [
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ragged tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 67 111 102 102 101 101], shape=(6,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(r[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[67, 111, 102, 102, 101, 101], [99, 97, 102, 102, 232]]>\n"
     ]
    }
   ],
   "source": [
    "print(r[1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[67, 97, 102, 233], [67, 111, 102, 102, 101, 101],\n",
      " [99, 97, 102, 102, 232], [21654, 21857], [65, 66], [], [67]]>\n"
     ]
    }
   ],
   "source": [
    "r2 = tf.ragged.constant([[65, 66], [], [67]])\n",
    "print(tf.concat([r, r2], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[67, 97, 102, 233, 68, 69, 70], [67, 111, 102, 102, 101, 101, 71],\n",
      " [99, 97, 102, 102, 232], [21654, 21857, 72, 73]]>\n"
     ]
    }
   ],
   "source": [
    "r3 = tf.ragged.constant([[68, 69, 70], [71], [], [72, 73]])\n",
    "print(tf.concat([r, r3], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=string, numpy=array([b'DEF', b'G', b'', b'HI'], dtype=object)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_encode(r3, \"UTF-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 6), dtype=int32, numpy=\n",
       "array([[   67,    97,   102,   233,     0,     0],\n",
       "       [   67,   111,   102,   102,   101,   101],\n",
       "       [   99,    97,   102,   102,   232,     0],\n",
       "       [21654, 21857,     0,     0,     0,     0]], dtype=int32)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.to_tensor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = tf.SparseTensor(indices=[[0, 1], [1, 0], [2, 3]],\n",
    "                    values=[1., 2., 3.],\n",
    "                    dense_shape=[3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseTensor(indices=tf.Tensor(\n",
      "[[0 1]\n",
      " [1 0]\n",
      " [2 3]], shape=(3, 2), dtype=int64), values=tf.Tensor([1. 2. 3.], shape=(3,), dtype=float32), dense_shape=tf.Tensor([3 4], shape=(2,), dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=float32, numpy=\n",
       "array([[0., 1., 0., 0.],\n",
       "       [2., 0., 0., 0.],\n",
       "       [0., 0., 0., 3.]], dtype=float32)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.sparse.to_dense(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = s * 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unsupported operand type(s) for +: 'SparseTensor' and 'float'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    s3 = s + 1.\n",
    "except TypeError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[ 30.,  40.],\n",
       "       [ 20.,  40.],\n",
       "       [210., 240.]], dtype=float32)>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s4 = tf.constant([[10., 20.], [30., 40.], [50., 60.], [70., 80.]])\n",
    "tf.sparse.sparse_dense_matmul(s, s4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseTensor(indices=tf.Tensor(\n",
      "[[0 2]\n",
      " [0 1]], shape=(2, 2), dtype=int64), values=tf.Tensor([1. 2.], shape=(2,), dtype=float32), dense_shape=tf.Tensor([3 4], shape=(2,), dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "s5 = tf.SparseTensor(indices=[[0, 2], [0, 1]],\n",
    "                     values=[1., 2.],\n",
    "                     dense_shape=[3, 4])\n",
    "print(s5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indices[1] is out of order. Many sparse ops require sorted indices.\n",
      "  Use `tf.sparse.reorder` to create a correctly ordered copy.\n",
      "\n",
      " [Op:SparseToDense]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tf.sparse.to_dense(s5)\n",
    "except tf.errors.InvalidArgumentError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=float32, numpy=\n",
       "array([[0., 2., 1., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s6 = tf.sparse.reorder(s5)\n",
    "tf.sparse.to_dense(s6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 6), dtype=int32, numpy=\n",
       "array([[ 2,  3,  4,  5,  6,  7],\n",
       "       [ 0,  7,  9, 10,  0,  0]], dtype=int32)>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set1 = tf.constant([[2, 3, 5, 7], [7, 9, 0, 0]])\n",
    "set2 = tf.constant([[4, 5, 6], [9, 10, 0]])\n",
    "tf.sparse.to_dense(tf.sets.union(set1, set2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "array([[2, 3, 7],\n",
       "       [7, 0, 0]], dtype=int32)>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.sparse.to_dense(tf.sets.difference(set1, set2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[5, 0],\n",
       "       [0, 9]], dtype=int32)>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.sparse.to_dense(tf.sets.intersection(set1, set2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = tf.Variable([[1., 2., 3.], [4., 5., 6.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2.,  4.,  6.],\n",
       "       [ 8., 10., 12.]], dtype=float32)>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.assign(2 * v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2., 42.,  6.],\n",
       "       [ 8., 10., 12.]], dtype=float32)>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[0, 1].assign(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2., 42.,  0.],\n",
       "       [ 8., 10.,  1.]], dtype=float32)>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[:, 2].assign([0., 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'ResourceVariable' object does not support item assignment\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    v[1] = [7., 8., 9.]\n",
    "except TypeError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[100.,  42.,   0.],\n",
       "       [  8.,  10., 200.]], dtype=float32)>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.scatter_nd_update(indices=[[0, 0], [1, 2]],\n",
    "                    updates=[100., 200.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[4., 5., 6.],\n",
       "       [1., 2., 3.]], dtype=float32)>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_delta = tf.IndexedSlices(values=[[1., 2., 3.], [4., 5., 6.]],\n",
    "                                indices=[1, 0])\n",
    "v.scatter_update(sparse_delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = tf.TensorArray(dtype=tf.float32, size=3)\n",
    "array = array.write(0, tf.constant([1., 2.]))\n",
    "array = array.write(1, tf.constant([3., 10.]))\n",
    "array = array.write(2, tf.constant([5., 7.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([ 3., 10.], dtype=float32)>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array.read(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[1., 2.],\n",
       "       [0., 0.],\n",
       "       [5., 7.]], dtype=float32)>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([2., 3.], dtype=float32)>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean, variance = tf.nn.moments(array.stack(), axes=0)\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([4.6666665, 8.666667 ], dtype=float32)>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by loading and preparing the California housing dataset. We first load it, then split it into a training set, a validation set and a test set, and finally we scale it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target.reshape(-1, 1), random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huber_fn(y_true, y_pred):\n",
    "    error = y_true - y_pred\n",
    "    is_small_error = tf.abs(error) < 1\n",
    "    squared_loss = tf.square(error) / 2\n",
    "    linear_loss  = tf.abs(error) - 0.5\n",
    "    return tf.where(is_small_error, squared_loss, linear_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x350 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 3.5))\n",
    "z = np.linspace(-4, 4, 200)\n",
    "plt.plot(z, huber_fn(0, z), \"b-\", linewidth=2, label=\"huber($z$)\")\n",
    "plt.plot(z, z**2 / 2, \"b:\", linewidth=1, label=r\"$\\frac{1}{2}z^2$\")\n",
    "plt.plot([-1, -1], [0, huber_fn(0., -1.)], \"r--\")\n",
    "plt.plot([1, 1], [0, huber_fn(0., 1.)], \"r--\")\n",
    "plt.gca().axhline(y=0, color='k')\n",
    "plt.gca().axvline(x=0, color='k')\n",
    "plt.axis([-4, 4, 0, 4])\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"$z$\")\n",
    "plt.legend(fontsize=14)\n",
    "plt.title(\"Huber loss\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=huber_fn, optimizer=\"nadam\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.6235 - mae: 0.9953 - val_loss: 0.2862 - val_mae: 0.5866\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2197 - mae: 0.5177 - val_loss: 0.2382 - val_mae: 0.5281\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8c805cf160>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving/Loading Models with Custom Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_a_custom_loss.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_model_with_a_custom_loss.h5\",\n",
    "                                custom_objects={\"huber_fn\": huber_fn})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.2054 - mae: 0.4982 - val_loss: 0.2209 - val_mae: 0.5050\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.1999 - mae: 0.4900 - val_loss: 0.2127 - val_mae: 0.4986\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8c803e5ca0>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_huber(threshold=1.0):\n",
    "    def huber_fn(y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < threshold\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss  = threshold * tf.abs(error) - threshold**2 / 2\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "    return huber_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=create_huber(2.0), optimizer=\"nadam\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.2226 - mae: 0.4892 - val_loss: 0.2539 - val_mae: 0.4907\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2184 - mae: 0.4844 - val_loss: 0.2372 - val_mae: 0.4879\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8c80408220>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_a_custom_loss_threshold_2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_model_with_a_custom_loss_threshold_2.h5\",\n",
    "                                custom_objects={\"huber_fn\": create_huber(2.0)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.2147 - mae: 0.4800 - val_loss: 0.2133 - val_mae: 0.4654\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2119 - mae: 0.4762 - val_loss: 0.1992 - val_mae: 0.4643\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8c80103e80>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuberLoss(keras.losses.Loss):\n",
    "    def __init__(self, threshold=1.0, **kwargs):\n",
    "        self.threshold = threshold\n",
    "        super().__init__(**kwargs)\n",
    "    def call(self, y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < self.threshold\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss  = self.threshold * tf.abs(error) - self.threshold**2 / 2\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"threshold\": self.threshold}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=HuberLoss(2.), optimizer=\"nadam\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.7095 - mae: 0.8863 - val_loss: 0.3378 - val_mae: 0.5485\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2416 - mae: 0.5083 - val_loss: 0.2660 - val_mae: 0.5089\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8c6c7ca250>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_a_custom_loss_class.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_model_with_a_custom_loss_class.h5\",\n",
    "                                custom_objects={\"HuberLoss\": HuberLoss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.2286 - mae: 0.4970 - val_loss: 0.2120 - val_mae: 0.4723\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2216 - mae: 0.4904 - val_loss: 0.2045 - val_mae: 0.4725\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8c6c656d60>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.loss.threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Custom Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_softplus(z): # return value is just tf.nn.softplus(z)\n",
    "    return tf.math.log(tf.exp(z) + 1.0)\n",
    "\n",
    "def my_glorot_initializer(shape, dtype=tf.float32):\n",
    "    stddev = tf.sqrt(2. / (shape[0] + shape[1]))\n",
    "    return tf.random.normal(shape, stddev=stddev, dtype=dtype)\n",
    "\n",
    "def my_l1_regularizer(weights):\n",
    "    return tf.reduce_sum(tf.abs(0.01 * weights))\n",
    "\n",
    "def my_positive_weights(weights): # return value is just tf.nn.relu(weights)\n",
    "    return tf.where(weights < 0., tf.zeros_like(weights), weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = keras.layers.Dense(1, activation=my_softplus,\n",
    "                           kernel_initializer=my_glorot_initializer,\n",
    "                           kernel_regularizer=my_l1_regularizer,\n",
    "                           kernel_constraint=my_positive_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1, activation=my_softplus,\n",
    "                       kernel_regularizer=my_l1_regularizer,\n",
    "                       kernel_constraint=my_positive_weights,\n",
    "                       kernel_initializer=my_glorot_initializer),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.5542 - mae: 0.8962 - val_loss: 1.4155 - val_mae: 0.5607\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5943 - mae: 0.5256 - val_loss: 1.4397 - val_mae: 0.5137\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8c6c54c280>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_many_custom_parts.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\n",
    "    \"my_model_with_many_custom_parts.h5\",\n",
    "    custom_objects={\n",
    "       \"my_l1_regularizer\": my_l1_regularizer,\n",
    "       \"my_positive_weights\": my_positive_weights,\n",
    "       \"my_glorot_initializer\": my_glorot_initializer,\n",
    "       \"my_softplus\": my_softplus,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyL1Regularizer(keras.regularizers.Regularizer):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "    def __call__(self, weights):\n",
    "        return tf.reduce_sum(tf.abs(self.factor * weights))\n",
    "    def get_config(self):\n",
    "        return {\"factor\": self.factor}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1, activation=my_softplus,\n",
    "                       kernel_regularizer=MyL1Regularizer(0.01),\n",
    "                       kernel_constraint=my_positive_weights,\n",
    "                       kernel_initializer=my_glorot_initializer),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.5542 - mae: 0.8962 - val_loss: 1.4155 - val_mae: 0.5607\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5943 - mae: 0.5256 - val_loss: 1.4397 - val_mae: 0.5137\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8c6c389310>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_many_custom_parts.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\n",
    "    \"my_model_with_many_custom_parts.h5\",\n",
    "    custom_objects={\n",
    "       \"MyL1Regularizer\": MyL1Regularizer,\n",
    "       \"my_positive_weights\": my_positive_weights,\n",
    "       \"my_glorot_initializer\": my_glorot_initializer,\n",
    "       \"my_softplus\": my_softplus,\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\", metrics=[create_huber(2.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 2.0982 - huber_fn: 0.9192\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6052 - huber_fn: 0.2733\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8c802e5190>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: if you use the same function as the loss and a metric, you may be surprised to see different results. This is generally just due to floating point precision errors: even though the mathematical equations are equivalent, the operations are not run in the same order, which can lead to small differences. Moreover, when using sample weights, there's more than just precision errors:\n",
    "* the loss since the start of the epoch is the mean of all batch losses seen so far. Each batch loss is the sum of the weighted instance losses divided by the _batch size_ (not the sum of weights, so the batch loss is _not_ the weighted mean of the losses).\n",
    "* the metric since the start of the epoch is equal to the sum of weighted instance losses divided by sum of all weights seen so far. In other words, it is the weighted mean of all the instance losses. Not the same thing.\n",
    "\n",
    "If you do the math, you will find that loss = metric * mean of sample weights (plus some floating point precision error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=create_huber(2.0), optimizer=\"nadam\", metrics=[create_huber(2.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.1175 - huber_fn: 0.2399\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.1131 - huber_fn: 0.2297\n"
     ]
    }
   ],
   "source": [
    "sample_weight = np.random.rand(len(y_train))\n",
    "history = model.fit(X_train_scaled, y_train, epochs=2, sample_weight=sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.11750346422195435, 0.11907085520758422)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history[\"loss\"][0], history.history[\"huber_fn\"][0] * sample_weight.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.8>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = keras.metrics.Precision()\n",
    "precision([0, 1, 1, 1, 0, 1, 0, 1], [1, 1, 0, 1, 0, 1, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.5>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision([0, 1, 0, 0, 1, 0, 1, 1], [1, 0, 1, 1, 0, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.5>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'true_positives:0' shape=(1,) dtype=float32, numpy=array([4.], dtype=float32)>,\n",
       " <tf.Variable 'false_positives:0' shape=(1,) dtype=float32, numpy=array([4.], dtype=float32)>]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a streaming metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuberMetric(keras.metrics.Metric):\n",
    "    def __init__(self, threshold=1.0, **kwargs):\n",
    "        super().__init__(**kwargs) # handles base args (e.g., dtype)\n",
    "        self.threshold = threshold\n",
    "        self.huber_fn = create_huber(threshold)\n",
    "        self.total = self.add_weight(\"total\", initializer=\"zeros\")\n",
    "        self.count = self.add_weight(\"count\", initializer=\"zeros\")\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        metric = self.huber_fn(y_true, y_pred)\n",
    "        self.total.assign_add(tf.reduce_sum(metric))\n",
    "        self.count.assign_add(tf.cast(tf.size(y_true), tf.float32))\n",
    "    def result(self):\n",
    "        return self.total / self.count\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"threshold\": self.threshold}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=14.0>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = HuberMetric(2.)\n",
    "\n",
    "# total = 2 * |10 - 2| - 2²/2 = 14\n",
    "# count = 1\n",
    "# result = 14 / 1 = 14\n",
    "m(tf.constant([[2.]]), tf.constant([[10.]])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=7.0>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total = total + (|1 - 0|² / 2) + (2 * |9.25 - 5| - 2² / 2) = 14 + 7 = 21\n",
    "# count = count + 2 = 3\n",
    "# result = total / count = 21 / 3 = 7\n",
    "m(tf.constant([[0.], [5.]]), tf.constant([[1.], [9.25]]))\n",
    "\n",
    "m.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'total:0' shape=() dtype=float32, numpy=21.0>,\n",
       " <tf.Variable 'count:0' shape=() dtype=float32, numpy=3.0>]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'total:0' shape=() dtype=float32, numpy=0.0>,\n",
       " <tf.Variable 'count:0' shape=() dtype=float32, numpy=0.0>]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.reset_states()\n",
    "m.variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that the `HuberMetric` class works well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=create_huber(2.0), optimizer=\"nadam\", metrics=[HuberMetric(2.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.8707 - huber_metric: 0.8707\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2595 - huber_metric: 0.2595\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8c2a71b550>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled.astype(np.float32), y_train.astype(np.float32), epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_a_custom_metric.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_model_with_a_custom_metric.h5\",\n",
    "                                custom_objects={\"huber_fn\": create_huber(2.0),\n",
    "                                                \"HuberMetric\": HuberMetric})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.2350 - huber_metric: 0.2350\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2278 - huber_metric: 0.2278\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8ccc2ec580>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled.astype(np.float32), y_train.astype(np.float32), epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning**: In TF 2.2, tf.keras adds an extra first metric in `model.metrics` at position 0 (see [TF issue #38150](https://github.com/tensorflow/tensorflow/issues/38150)). This forces us to use `model.metrics[-1]` rather than `model.metrics[0]` to access the `HuberMetric`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics[-1].threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like it works fine! More simply, we could have created the class like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuberMetric(keras.metrics.Mean):\n",
    "    def __init__(self, threshold=1.0, name='HuberMetric', dtype=None):\n",
    "        self.threshold = threshold\n",
    "        self.huber_fn = create_huber(threshold)\n",
    "        super().__init__(name=name, dtype=dtype)\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        metric = self.huber_fn(y_true, y_pred)\n",
    "        super(HuberMetric, self).update_state(metric, sample_weight)\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"threshold\": self.threshold}        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class handles shapes better, and it also supports sample weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.Huber(2.0), optimizer=\"nadam\", weighted_metrics=[HuberMetric(2.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4455 - HuberMetric: 0.8978\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.1305 - HuberMetric: 0.2631\n"
     ]
    }
   ],
   "source": [
    "sample_weight = np.random.rand(len(y_train))\n",
    "history = model.fit(X_train_scaled.astype(np.float32), y_train.astype(np.float32),\n",
    "                    epochs=2, sample_weight=sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.44554603099823, 0.445546082726131)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history[\"loss\"][0], history.history[\"HuberMetric\"][0] * sample_weight.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_a_custom_metric_v2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_model_with_a_custom_metric_v2.h5\",\n",
    "                                custom_objects={\"HuberMetric\": HuberMetric})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.2377 - HuberMetric: 0.2377\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2279 - HuberMetric: 0.2279\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8c2821c9d0>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled.astype(np.float32), y_train.astype(np.float32), epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics[-1].threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "exponential_layer = keras.layers.Lambda(lambda x: tf.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0.36787948, 1.        , 2.7182817 ], dtype=float32)>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exponential_layer([-1., 0., 1.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding an exponential layer at the output of a regression model can be useful if the values to predict are positive and with very different scales (e.g., 0.001, 10., 10000):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "363/363 [==============================] - 0s 994us/step - loss: 1.0624 - val_loss: 0.4475\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 0s 862us/step - loss: 0.4540 - val_loss: 0.3792\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 0s 880us/step - loss: 0.4027 - val_loss: 0.3545\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 0s 874us/step - loss: 0.3843 - val_loss: 0.3457\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 0s 878us/step - loss: 0.3704 - val_loss: 0.3451\n",
      "162/162 [==============================] - 0s 559us/step - loss: 0.3595\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3594556450843811"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "    exponential_layer\n",
    "])\n",
    "model.compile(loss=\"mse\", optimizer=\"sgd\")\n",
    "model.fit(X_train_scaled, y_train, epochs=5,\n",
    "          validation_data=(X_valid_scaled, y_valid))\n",
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDense(keras.layers.Layer):\n",
    "    def __init__(self, units, activation=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.activation = keras.activations.get(activation)\n",
    "\n",
    "    def build(self, batch_input_shape):\n",
    "        self.kernel = self.add_weight(\n",
    "            name=\"kernel\", shape=[batch_input_shape[-1], self.units],\n",
    "            initializer=\"glorot_normal\")\n",
    "        self.bias = self.add_weight(\n",
    "            name=\"bias\", shape=[self.units], initializer=\"zeros\")\n",
    "        super().build(batch_input_shape) # must be at the end\n",
    "\n",
    "    def call(self, X):\n",
    "        return self.activation(X @ self.kernel + self.bias)\n",
    "\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return tf.TensorShape(batch_input_shape.as_list()[:-1] + [self.units])\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"units\": self.units,\n",
    "                \"activation\": keras.activations.serialize(self.activation)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    MyDense(30, activation=\"relu\", input_shape=input_shape),\n",
    "    MyDense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 2.2563 - val_loss: 0.9473\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6485 - val_loss: 0.6219\n",
      "162/162 [==============================] - 0s 549us/step - loss: 0.5474\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5473757982254028"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))\n",
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_a_custom_layer.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_model_with_a_custom_layer.h5\",\n",
    "                                custom_objects={\"MyDense\": MyDense})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMultiLayer(keras.layers.Layer):\n",
    "    def call(self, X):\n",
    "        X1, X2 = X\n",
    "        print(\"X1.shape: \", X1.shape ,\" X2.shape: \", X2.shape) # Debugging of custom layer\n",
    "        return X1 + X2, X1 * X2\n",
    "\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        batch_input_shape1, batch_input_shape2 = batch_input_shape\n",
    "        return [batch_input_shape1, batch_input_shape2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our custom layer can be called using the functional API like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1.shape:  (None, 2)  X2.shape:  (None, 2)\n"
     ]
    }
   ],
   "source": [
    "inputs1 = keras.layers.Input(shape=[2])\n",
    "inputs2 = keras.layers.Input(shape=[2])\n",
    "outputs1, outputs2 = MyMultiLayer()((inputs1, inputs2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `call()` method receives symbolic inputs, whose shape is only partially specified (at this stage, we don't know the batch size, which is why the first dimension is `None`):\n",
    "\n",
    "We can also pass actual data to the custom layer. To test this, let's split each dataset's inputs into two parts, with four features each:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11610, 4), (11610, 4))"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_data(data):\n",
    "    columns_count = data.shape[-1]\n",
    "    half = columns_count // 2\n",
    "    return data[:, :half], data[:, half:]\n",
    "\n",
    "X_train_scaled_A, X_train_scaled_B = split_data(X_train_scaled)\n",
    "X_valid_scaled_A, X_valid_scaled_B = split_data(X_valid_scaled)\n",
    "X_test_scaled_A, X_test_scaled_B = split_data(X_test_scaled)\n",
    "\n",
    "# Printing the splitted data shapes\n",
    "X_train_scaled_A.shape, X_train_scaled_B.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now notice that the shapes are fully specified:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1.shape:  (11610, 4)  X2.shape:  (11610, 4)\n"
     ]
    }
   ],
   "source": [
    "outputs1, outputs2 = MyMultiLayer()((X_train_scaled_A, X_train_scaled_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a more complete model using the functional API (this is just a toy example, don't expect awesome performance):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1.shape:  (None, 4)  X2.shape:  (None, 4)\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "input_A = keras.layers.Input(shape=X_train_scaled_A.shape[-1])\n",
    "input_B = keras.layers.Input(shape=X_train_scaled_B.shape[-1])\n",
    "hidden_A, hidden_B = MyMultiLayer()((input_A, input_B))\n",
    "hidden_A = keras.layers.Dense(30, activation='selu')(hidden_A)\n",
    "hidden_B = keras.layers.Dense(30, activation='selu')(hidden_B)\n",
    "concat = keras.layers.Concatenate()((hidden_A, hidden_B))\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.models.Model(inputs=[input_A, input_B], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='nadam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "X1.shape:  (None, 4)  X2.shape:  (None, 4)\n",
      "X1.shape:  (None, 4)  X2.shape:  (None, 4)\n",
      "336/363 [==========================>...] - ETA: 0s - loss: 2.2056X1.shape:  (None, 4)  X2.shape:  (None, 4)\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.1142 - val_loss: 1.3629\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.9684 - val_loss: 0.9772\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8c1c6bdc40>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit((X_train_scaled_A, X_train_scaled_B), y_train, epochs=2,\n",
    "          validation_data=((X_valid_scaled_A, X_valid_scaled_B), y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a layer with a different behavior during training and testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddGaussianNoise(keras.layers.Layer):\n",
    "    def __init__(self, stddev, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.stddev = stddev\n",
    "\n",
    "    def call(self, X, training=None):\n",
    "        if training:\n",
    "            noise = tf.random.normal(tf.shape(X), stddev=self.stddev)\n",
    "            return X + noise\n",
    "        else:\n",
    "            return X\n",
    "\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return batch_input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a simple model that uses this custom layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    AddGaussianNoise(stddev=1.0),\n",
    "    keras.layers.Dense(30, activation=\"selu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 2.3857 - val_loss: 7.6084\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.0571 - val_loss: 4.4599\n",
      "162/162 [==============================] - 0s 551us/step - loss: 0.7560\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7559574246406555"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))\n",
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new_scaled = X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(keras.layers.Layer):\n",
    "    def __init__(self, n_layers, n_neurons, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden = [keras.layers.Dense(n_neurons, activation=\"elu\",\n",
    "                                          kernel_initializer=\"he_normal\")\n",
    "                       for _ in range(n_layers)]\n",
    "\n",
    "    def call(self, inputs):\n",
    "        Z = inputs\n",
    "        for layer in self.hidden:\n",
    "            Z = layer(Z)\n",
    "        return inputs + Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualRegressor(keras.models.Model):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = keras.layers.Dense(30, activation=\"elu\",\n",
    "                                          kernel_initializer=\"he_normal\")\n",
    "        self.block1 = ResidualBlock(2, 30)\n",
    "        self.block2 = ResidualBlock(2, 30)\n",
    "        self.out = keras.layers.Dense(output_dim)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        Z = self.hidden1(inputs)\n",
    "        for _ in range(1 + 3):\n",
    "            Z = self.block1(Z)\n",
    "        Z = self.block2(Z)\n",
    "        return self.out(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 9.3332\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.2086\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.8384\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7136\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6150\n",
      "162/162 [==============================] - 0s 746us/step - loss: 0.6340\n",
      "162/162 [==============================] - 0s 640us/step\n"
     ]
    }
   ],
   "source": [
    "model = ResidualRegressor(1)\n",
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "history = model.fit(X_train_scaled, y_train, epochs=5)\n",
    "score = model.evaluate(X_test_scaled, y_test)\n",
    "y_pred = model.predict(X_new_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses, dense_2_layer_call_fn, dense_2_layer_call_and_return_conditional_losses, dense_3_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_custom_model.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_custom_model.ckpt/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"my_custom_model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_custom_model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.8263\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.1278\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5555\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6316\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4944\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could have defined the model using the sequential API instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "block1 = ResidualBlock(2, 30)\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    block1, block1, block1, block1,\n",
    "    ResidualBlock(2, 30),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.8695\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4715\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5528\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3817\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4027\n",
      "162/162 [==============================] - 0s 643us/step - loss: 0.4862\n",
      "162/162 [==============================] - 0s 510us/step\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "history = model.fit(X_train_scaled, y_train, epochs=5)\n",
    "score = model.evaluate(X_test_scaled, y_test)\n",
    "y_pred = model.predict(X_new_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Losses and Metrics Based on Model Internals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: the following code has two differences with the code in the book:\n",
    "1. It creates a `keras.metrics.Mean()` metric in the constructor and uses it in the `call()` method to track the mean reconstruction loss. Since we only want to do this during training, we add a `training` argument to the `call()` method, and if `training` is `True`, then we update `reconstruction_mean` and we call `self.add_metric()` to ensure it's displayed properly.\n",
    "2. Due to an issue introduced in TF 2.2 ([#46858](https://github.com/tensorflow/tensorflow/issues/46858)), we must not call `super().build()` inside the `build()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReconstructingRegressor(keras.Model):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden = [keras.layers.Dense(30, activation=\"selu\",\n",
    "                                          kernel_initializer=\"lecun_normal\")\n",
    "                       for _ in range(5)]\n",
    "        self.out = keras.layers.Dense(output_dim)\n",
    "        self.reconstruction_mean = keras.metrics.Mean(name=\"reconstruction_error\")\n",
    "\n",
    "    def build(self, batch_input_shape):\n",
    "        n_inputs = batch_input_shape[-1]\n",
    "        self.reconstruct = keras.layers.Dense(n_inputs)\n",
    "        #super().build(batch_input_shape)\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        Z = inputs\n",
    "        for layer in self.hidden:\n",
    "            Z = layer(Z)\n",
    "        reconstruction = self.reconstruct(Z)\n",
    "        recon_loss = tf.reduce_mean(tf.square(reconstruction - inputs))\n",
    "        self.add_loss(0.05 * recon_loss)\n",
    "        if training:\n",
    "            result = self.reconstruction_mean(recon_loss)\n",
    "            self.add_metric(result)\n",
    "        return self.out(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7881 - reconstruction_error: 1.0474\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4136 - reconstruction_error: 0.4041\n",
      "162/162 [==============================] - 0s 515us/step\n"
     ]
    }
   ],
   "source": [
    "model = ReconstructingRegressor(1)\n",
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "history = model.fit(X_train_scaled, y_train, epochs=2)\n",
    "y_pred = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Gradients with Autodiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(w1, w2):\n",
    "    return 3 * w1 ** 2 + 2 * w1 * w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.000003007075065"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1, w2 = 5, 3\n",
    "eps = 1e-6\n",
    "(f(w1 + eps, w2) - f(w1, w2)) / eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.000000003174137"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(f(w1, w2 + eps) - f(w1, w2)) / eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1, w2 = tf.Variable(5.), tf.Variable(3.)\n",
    "with tf.GradientTape() as tape:\n",
    "    z = f(w1, w2)\n",
    "\n",
    "gradients = tape.gradient(z, [w1, w2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A non-persistent GradientTape can only be used to compute one set of gradients (or jacobians)\n"
     ]
    }
   ],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    z = f(w1, w2)\n",
    "\n",
    "dz_dw1 = tape.gradient(z, w1)\n",
    "try:\n",
    "    dz_dw2 = tape.gradient(z, w2)\n",
    "except RuntimeError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    z = f(w1, w2)\n",
    "\n",
    "dz_dw1 = tape.gradient(z, w1)\n",
    "dz_dw2 = tape.gradient(z, w2) # works now!\n",
    "del tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dz_dw1, dz_dw2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1, c2 = tf.constant(5.), tf.constant(3.)\n",
    "with tf.GradientTape() as tape:\n",
    "    z = f(c1, c2)\n",
    "\n",
    "gradients = tape.gradient(z, [c1, c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(c1)\n",
    "    tape.watch(c2)\n",
    "    z = f(c1, c2)\n",
    "\n",
    "gradients = tape.gradient(z, [c1, c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=136.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=30.0>]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    z1 = f(w1, w2 + 2.)\n",
    "    z2 = f(w1, w2 + 5.)\n",
    "    z3 = f(w1, w2 + 7.)\n",
    "\n",
    "tape.gradient([z1, z2, z3], [w1, w2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    z1 = f(w1, w2 + 2.)\n",
    "    z2 = f(w1, w2 + 5.)\n",
    "    z3 = f(w1, w2 + 7.)\n",
    "\n",
    "tf.reduce_sum(tf.stack([tape.gradient(z, [w1, w2]) for z in (z1, z2, z3)]), axis=0)\n",
    "del tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape(persistent=True) as hessian_tape:\n",
    "    with tf.GradientTape() as jacobian_tape:\n",
    "        z = f(w1, w2)\n",
    "    jacobians = jacobian_tape.gradient(z, [w1, w2])\n",
    "hessians = [hessian_tape.gradient(jacobian, [w1, w2])\n",
    "            for jacobian in jacobians]\n",
    "del hessian_tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[<tf.Tensor: shape=(), dtype=float32, numpy=6.0>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=2.0>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=2.0>, None]]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hessians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=30.0>, None]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(w1, w2):\n",
    "    return 3 * w1 ** 2 + tf.stop_gradient(2 * w1 * w2)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    z = f(w1, w2)\n",
    "\n",
    "tape.gradient(z, [w1, w2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=nan>]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.Variable(100.)\n",
    "with tf.GradientTape() as tape:\n",
    "    z = my_softplus(x)\n",
    "\n",
    "tape.gradient(z, [x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=30.0>"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.log(tf.exp(tf.constant(30., dtype=tf.float32)) + 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(1,), dtype=float32, numpy=array([nan], dtype=float32)>]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.Variable([100.])\n",
    "with tf.GradientTape() as tape:\n",
    "    z = my_softplus(x)\n",
    "\n",
    "tape.gradient(z, [x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.custom_gradient\n",
    "def my_better_softplus(z):\n",
    "    exp = tf.exp(z)\n",
    "    def my_softplus_gradients(grad):\n",
    "        return grad / (1 + 1 / exp)\n",
    "    return tf.math.log(exp + 1), my_softplus_gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_better_softplus(z):\n",
    "    return tf.where(z > 30., z, tf.math.log(tf.exp(z) + 1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1000.], dtype=float32)>,\n",
       " [<tf.Tensor: shape=(1,), dtype=float32, numpy=array([nan], dtype=float32)>])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.Variable([1000.])\n",
    "with tf.GradientTape() as tape:\n",
    "    z = my_better_softplus(x)\n",
    "\n",
    "z, tape.gradient(z, [x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing Gradients Using Autodiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_reg = keras.regularizers.l2(0.05)\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"elu\", kernel_initializer=\"he_normal\",\n",
    "                       kernel_regularizer=l2_reg),\n",
    "    keras.layers.Dense(1, kernel_regularizer=l2_reg)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_batch(X, y, batch_size=32):\n",
    "    idx = np.random.randint(len(X), size=batch_size)\n",
    "    return X[idx], y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_status_bar(iteration, total, loss, metrics=None):\n",
    "    metrics = \" - \".join([\"{}: {:.4f}\".format(m.name, m.result())\n",
    "                         for m in [loss] + (metrics or [])])\n",
    "    end = \"\" if iteration < total else \"\\n\"\n",
    "    print(\"\\r{}/{} - \".format(iteration, total) + metrics,\n",
    "          end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 - loss: 0.0900 - mean_square: 858.5000\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "mean_loss = keras.metrics.Mean(name=\"loss\")\n",
    "mean_square = keras.metrics.Mean(name=\"mean_square\")\n",
    "for i in range(1, 50 + 1):\n",
    "    loss = 1 / i\n",
    "    mean_loss(loss)\n",
    "    mean_square(i ** 2)\n",
    "    print_status_bar(i, 50, mean_loss, [mean_square])\n",
    "    time.sleep(0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A fancier version with a progress bar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def progress_bar(iteration, total, size=30):\n",
    "    running = iteration < total\n",
    "    c = \">\" if running else \"=\"\n",
    "    p = (size - 1) * iteration // total\n",
    "    fmt = \"{{:-{}d}}/{{}} [{{}}]\".format(len(str(total)))\n",
    "    params = [iteration, total, \"=\" * p + c + \".\" * (size - p - 1)]\n",
    "    return fmt.format(*params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 3500/10000 [=>....]'"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "progress_bar(3500, 10000, size=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_status_bar(iteration, total, loss, metrics=None, size=30):\n",
    "    metrics = \" - \".join([\"{}: {:.4f}\".format(m.name, m.result())\n",
    "                         for m in [loss] + (metrics or [])])\n",
    "    end = \"\" if iteration < total else \"\\n\"\n",
    "    print(\"\\r{} - {}\".format(progress_bar(iteration, total), metrics), end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - loss: 0.0900 - mean_square: 858.5000\n"
     ]
    }
   ],
   "source": [
    "mean_loss = keras.metrics.Mean(name=\"loss\")\n",
    "mean_square = keras.metrics.Mean(name=\"mean_square\")\n",
    "for i in range(1, 50 + 1):\n",
    "    loss = 1 / i\n",
    "    mean_loss(loss)\n",
    "    mean_square(i ** 2)\n",
    "    print_status_bar(i, 50, mean_loss, [mean_square])\n",
    "    time.sleep(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "batch_size = 32\n",
    "n_steps = len(X_train) // batch_size\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "loss_fn = keras.losses.mean_squared_error\n",
    "mean_loss = keras.metrics.Mean()\n",
    "metrics = [keras.metrics.MeanAbsoluteError()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "11610/11610 [==============================] - mean: 1.3956 - mean_absolute_error: 0.5722\n",
      "Epoch 2/5\n",
      "11610/11610 [==============================] - mean: 0.6774 - mean_absolute_error: 0.5280\n",
      "Epoch 3/5\n",
      "11610/11610 [==============================] - mean: 0.6351 - mean_absolute_error: 0.5177\n",
      "Epoch 4/5\n",
      "11610/11610 [==============================] - mean: 0.6384 - mean_absolute_error: 0.5181\n",
      "Epoch 5/5\n",
      "11610/11610 [==============================] - mean: 0.6440 - mean_absolute_error: 0.5222\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs + 1):\n",
    "    print(\"Epoch {}/{}\".format(epoch, n_epochs))\n",
    "    for step in range(1, n_steps + 1):\n",
    "        X_batch, y_batch = random_batch(X_train_scaled, y_train)\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(X_batch)\n",
    "            main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "            loss = tf.add_n([main_loss] + model.losses)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        for variable in model.variables:\n",
    "            if variable.constraint is not None:\n",
    "                variable.assign(variable.constraint(variable))\n",
    "        mean_loss(loss)\n",
    "        for metric in metrics:\n",
    "            metric(y_batch, y_pred)\n",
    "        print_status_bar(step * batch_size, len(y_train), mean_loss, metrics)\n",
    "    print_status_bar(len(y_train), len(y_train), mean_loss, metrics)\n",
    "    for metric in [mean_loss] + metrics:\n",
    "        metric.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "057b7c2d2686483aa3f5c2d93335a1e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "All epochs:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d795f55b7c64f038f59c371fa28f027",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/5:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "957dca8bfcd24bbea5d6bf7102b90268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/5:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73c8a43a96dc44fdaf88f4d3263a8a07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/5:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "495d2b9d287e45e1bdf0e08f3ee29380",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/5:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff23b434fe7a4065a9ab1d7d0c6a6670",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/5:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    from tqdm.notebook import trange\n",
    "    from collections import OrderedDict\n",
    "    with trange(1, n_epochs + 1, desc=\"All epochs\") as epochs:\n",
    "        for epoch in epochs:\n",
    "            with trange(1, n_steps + 1, desc=\"Epoch {}/{}\".format(epoch, n_epochs)) as steps:\n",
    "                for step in steps:\n",
    "                    X_batch, y_batch = random_batch(X_train_scaled, y_train)\n",
    "                    with tf.GradientTape() as tape:\n",
    "                        y_pred = model(X_batch)\n",
    "                        main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "                        loss = tf.add_n([main_loss] + model.losses)\n",
    "                    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "                    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "                    for variable in model.variables:\n",
    "                        if variable.constraint is not None:\n",
    "                            variable.assign(variable.constraint(variable))                    \n",
    "                    status = OrderedDict()\n",
    "                    mean_loss(loss)\n",
    "                    status[\"loss\"] = mean_loss.result().numpy()\n",
    "                    for metric in metrics:\n",
    "                        metric(y_batch, y_pred)\n",
    "                        status[metric.name] = metric.result().numpy()\n",
    "                    steps.set_postfix(status)\n",
    "            for metric in [mean_loss] + metrics:\n",
    "                metric.reset_states()\n",
    "except ImportError as ex:\n",
    "    print(\"To run this cell, please install tqdm, ipywidgets and restart Jupyter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cube(x):\n",
    "    return x ** 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.eager.def_function.Function at 0x7f8c0c3975e0>"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube = tf.function(cube)\n",
    "tf_cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=8>"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF Functions and Concrete Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.framework.func_graph.FuncGraph at 0x7f8c0c1e5970>"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function = tf_cube.get_concrete_function(tf.constant(2.0))\n",
    "concrete_function.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function is tf_cube.get_concrete_function(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Function Definitions and Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.framework.func_graph.FuncGraph at 0x7f8c0c1e5970>"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'x' type=Placeholder>,\n",
       " <tf.Operation 'pow/y' type=Const>,\n",
       " <tf.Operation 'pow' type=Pow>,\n",
       " <tf.Operation 'Identity' type=Identity>]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ops = concrete_function.graph.get_operations()\n",
    "ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'x:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'pow/y:0' shape=() dtype=float32>]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pow_op = ops[2]\n",
    "list(pow_op.inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'pow:0' shape=() dtype=float32>]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pow_op.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Operation 'x' type=Placeholder>"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function.graph.get_operation_by_name('x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Identity:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function.graph.get_tensor_by_name('Identity:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"__inference_cube_1133514\"\n",
       "input_arg {\n",
       "  name: \"x\"\n",
       "  type: DT_FLOAT\n",
       "}\n",
       "output_arg {\n",
       "  name: \"identity\"\n",
       "  type: DT_FLOAT\n",
       "}"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function.function_def.signature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How TF Functions Trace Python Functions to Extract Their Computation Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def tf_cube(x):\n",
    "    print(\"print:\", x)\n",
    "    return x ** 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print: Tensor(\"x:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "result = tf_cube(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print: 2\n",
      "print: 3\n",
      "print: Tensor(\"x:0\", shape=(1, 2), dtype=float32)\n",
      "print: Tensor(\"x:0\", shape=(2, 2), dtype=float32)\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function tf_cube at 0x7f8c0c1f7430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function tf_cube at 0x7f8c0c1f7430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print: Tensor(\"x:0\", shape=(3, 2), dtype=float32)\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function tf_cube at 0x7f8c0c1f7430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function tf_cube at 0x7f8c0c1f7430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "result = tf_cube(2)\n",
    "result = tf_cube(3)\n",
    "result = tf_cube(tf.constant([[1., 2.]])) # New shape: trace!\n",
    "result = tf_cube(tf.constant([[3., 4.], [5., 6.]])) # New shape: trace!\n",
    "result = tf_cube(tf.constant([[7., 8.], [9., 10.], [11., 12.]])) # New shape: trace!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to specify a particular input signature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(input_signature=[tf.TensorSpec([None, 28, 28], tf.float32)])\n",
    "def shrink(images):\n",
    "    print(\"Tracing\", images)\n",
    "    return images[:, ::2, ::2] # drop half the rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing Tensor(\"images:0\", shape=(None, 28, 28), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "img_batch_1 = tf.random.uniform(shape=[100, 28, 28])\n",
    "img_batch_2 = tf.random.uniform(shape=[50, 28, 28])\n",
    "preprocessed_images = shrink(img_batch_1) # Traces the function.\n",
    "preprocessed_images = shrink(img_batch_2) # Reuses the same concrete function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python inputs incompatible with input_signature:\n",
      "  inputs: (\n",
      "    tf.Tensor(\n",
      "[[[0.7413678  0.62854624]\n",
      "  [0.01738465 0.3431449 ]]\n",
      "\n",
      " [[0.51063764 0.3777541 ]\n",
      "  [0.07321596 0.02137029]]], shape=(2, 2, 2), dtype=float32))\n",
      "  input_signature: (\n",
      "    TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name=None)).\n"
     ]
    }
   ],
   "source": [
    "img_batch_3 = tf.random.uniform(shape=[2, 2, 2])\n",
    "try:\n",
    "    preprocessed_images = shrink(img_batch_3)  # rejects unexpected types or shapes\n",
    "except ValueError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Autograph To Capture Control Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A \"static\" `for` loop using `range()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def add_10(x):\n",
    "    for i in range(10):\n",
    "        x += 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=15>"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_10(tf.constant(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'x' type=Placeholder>,\n",
       " <tf.Operation 'add/y' type=Const>,\n",
       " <tf.Operation 'add' type=AddV2>,\n",
       " <tf.Operation 'add_1/y' type=Const>,\n",
       " <tf.Operation 'add_1' type=AddV2>,\n",
       " <tf.Operation 'add_2/y' type=Const>,\n",
       " <tf.Operation 'add_2' type=AddV2>,\n",
       " <tf.Operation 'add_3/y' type=Const>,\n",
       " <tf.Operation 'add_3' type=AddV2>,\n",
       " <tf.Operation 'add_4/y' type=Const>,\n",
       " <tf.Operation 'add_4' type=AddV2>,\n",
       " <tf.Operation 'add_5/y' type=Const>,\n",
       " <tf.Operation 'add_5' type=AddV2>,\n",
       " <tf.Operation 'add_6/y' type=Const>,\n",
       " <tf.Operation 'add_6' type=AddV2>,\n",
       " <tf.Operation 'add_7/y' type=Const>,\n",
       " <tf.Operation 'add_7' type=AddV2>,\n",
       " <tf.Operation 'add_8/y' type=Const>,\n",
       " <tf.Operation 'add_8' type=AddV2>,\n",
       " <tf.Operation 'add_9/y' type=Const>,\n",
       " <tf.Operation 'add_9' type=AddV2>,\n",
       " <tf.Operation 'Identity' type=Identity>]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_10.get_concrete_function(tf.constant(5)).graph.get_operations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A \"dynamic\" loop using `tf.while_loop()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def add_10(x):\n",
    "    condition = lambda i, x: tf.less(i, 10)\n",
    "    body = lambda i, x: (tf.add(i, 1), tf.add(x, 1))\n",
    "    final_i, final_x = tf.while_loop(condition, body, [tf.constant(0), x])\n",
    "    return final_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=15>"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_10(tf.constant(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'x' type=Placeholder>,\n",
       " <tf.Operation 'Const' type=Const>,\n",
       " <tf.Operation 'while/maximum_iterations' type=Const>,\n",
       " <tf.Operation 'while/loop_counter' type=Const>,\n",
       " <tf.Operation 'while' type=StatelessWhile>,\n",
       " <tf.Operation 'Identity' type=Identity>]"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_10.get_concrete_function(tf.constant(5)).graph.get_operations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A \"dynamic\" `for` loop using `tf.range()` (captured by autograph):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def add_10(x):\n",
    "    for i in tf.range(10):\n",
    "        x = x + 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'x' type=Placeholder>,\n",
       " <tf.Operation 'range/start' type=Const>,\n",
       " <tf.Operation 'range/limit' type=Const>,\n",
       " <tf.Operation 'range/delta' type=Const>,\n",
       " <tf.Operation 'range' type=Range>,\n",
       " <tf.Operation 'sub' type=Sub>,\n",
       " <tf.Operation 'floordiv' type=FloorDiv>,\n",
       " <tf.Operation 'mod' type=FloorMod>,\n",
       " <tf.Operation 'zeros_like' type=Const>,\n",
       " <tf.Operation 'NotEqual' type=NotEqual>,\n",
       " <tf.Operation 'Cast' type=Cast>,\n",
       " <tf.Operation 'add' type=AddV2>,\n",
       " <tf.Operation 'zeros_like_1' type=Const>,\n",
       " <tf.Operation 'Maximum' type=Maximum>,\n",
       " <tf.Operation 'while/maximum_iterations' type=Const>,\n",
       " <tf.Operation 'while/loop_counter' type=Const>,\n",
       " <tf.Operation 'while' type=StatelessWhile>,\n",
       " <tf.Operation 'Identity' type=Identity>]"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_10.get_concrete_function(tf.constant(0)).graph.get_operations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Variables and Other Resources in TF Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = tf.Variable(0)\n",
    "\n",
    "@tf.function\n",
    "def increment(counter, c=1):\n",
    "    return counter.assign_add(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=2>"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "increment(counter)\n",
    "increment(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"counter\"\n",
       "type: DT_RESOURCE"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_def = increment.get_concrete_function(counter).function_def\n",
    "function_def.signature.input_arg[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = tf.Variable(0)\n",
    "\n",
    "@tf.function\n",
    "def increment(c=1):\n",
    "    return counter.assign_add(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=2>"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "increment()\n",
    "increment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"assignaddvariableop_resource\"\n",
       "type: DT_RESOURCE"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_def = increment.get_concrete_function().function_def\n",
    "function_def.signature.input_arg[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Counter:\n",
    "    def __init__(self):\n",
    "        self.counter = tf.Variable(0)\n",
    "\n",
    "    @tf.function\n",
    "    def increment(self, c=1):\n",
    "        return self.counter.assign_add(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=2>"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = Counter()\n",
    "c.increment()\n",
    "c.increment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def tf__add(x):\n",
      "    with ag__.FunctionScope('add_10', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\n",
      "        do_return = False\n",
      "        retval_ = ag__.UndefinedReturnValue()\n",
      "\n",
      "        def get_state():\n",
      "            return (x,)\n",
      "\n",
      "        def set_state(vars_):\n",
      "            nonlocal x\n",
      "            (x,) = vars_\n",
      "\n",
      "        def loop_body(itr):\n",
      "            nonlocal x\n",
      "            i = itr\n",
      "            x = ag__.ld(x)\n",
      "            x += 1\n",
      "        i = ag__.Undefined('i')\n",
      "        ag__.for_stmt(ag__.converted_call(ag__.ld(tf).range, (10,), None, fscope), None, loop_body, get_state, set_state, ('x',), {'iterate_names': 'i'})\n",
      "        try:\n",
      "            do_return = True\n",
      "            retval_ = ag__.ld(x)\n",
      "        except:\n",
      "            do_return = False\n",
      "            raise\n",
      "        return fscope.ret(retval_, do_return)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def add_10(x):\n",
    "    for i in tf.range(10):\n",
    "        x += 1\n",
    "    return x\n",
    "\n",
    "print(tf.autograph.to_code(add_10.python_function))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_tf_code(func):\n",
    "    from IPython.display import display, Markdown\n",
    "    if hasattr(func, \"python_function\"):\n",
    "        func = func.python_function\n",
    "    code = tf.autograph.to_code(func)\n",
    "    display(Markdown('```python\\n{}\\n```'.format(code)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "def tf__add(x):\n",
       "    with ag__.FunctionScope('add_10', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\n",
       "        do_return = False\n",
       "        retval_ = ag__.UndefinedReturnValue()\n",
       "\n",
       "        def get_state():\n",
       "            return (x,)\n",
       "\n",
       "        def set_state(vars_):\n",
       "            nonlocal x\n",
       "            (x,) = vars_\n",
       "\n",
       "        def loop_body(itr):\n",
       "            nonlocal x\n",
       "            i = itr\n",
       "            x = ag__.ld(x)\n",
       "            x += 1\n",
       "        i = ag__.Undefined('i')\n",
       "        ag__.for_stmt(ag__.converted_call(ag__.ld(tf).range, (10,), None, fscope), None, loop_body, get_state, set_state, ('x',), {'iterate_names': 'i'})\n",
       "        try:\n",
       "            do_return = True\n",
       "            retval_ = ag__.ld(x)\n",
       "        except:\n",
       "            do_return = False\n",
       "            raise\n",
       "        return fscope.ret(retval_, do_return)\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_tf_code(add_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using TF Functions with tf.keras (or Not)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, tf.keras will automatically convert your custom code into TF Functions, no need to use\n",
    "`tf.function()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom loss function\n",
    "def my_mse(y_true, y_pred):\n",
    "    print(\"Tracing loss my_mse()\")\n",
    "    return tf.reduce_mean(tf.square(y_pred - y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom metric function\n",
    "def my_mae(y_true, y_pred):\n",
    "    print(\"Tracing metric my_mae()\")\n",
    "    return tf.reduce_mean(tf.abs(y_pred - y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom layer\n",
    "class MyDense(keras.layers.Layer):\n",
    "    def __init__(self, units, activation=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.activation = keras.activations.get(activation)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(name='kernel', \n",
    "                                      shape=(input_shape[1], self.units),\n",
    "                                      initializer='uniform',\n",
    "                                      trainable=True)\n",
    "        self.biases = self.add_weight(name='bias', \n",
    "                                      shape=(self.units,),\n",
    "                                      initializer='zeros',\n",
    "                                      trainable=True)\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, X):\n",
    "        print(\"Tracing MyDense.call()\")\n",
    "        return self.activation(X @ self.kernel + self.biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom model\n",
    "class MyModel(keras.models.Model):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = MyDense(30, activation=\"relu\")\n",
    "        self.hidden2 = MyDense(30, activation=\"relu\")\n",
    "        self.output_ = MyDense(1)\n",
    "\n",
    "    def call(self, input):\n",
    "        print(\"Tracing MyModel.call()\")\n",
    "        hidden1 = self.hidden1(input)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([input, hidden2])\n",
    "        output = self.output_(concat)\n",
    "        return output\n",
    "\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=my_mse, optimizer=\"nadam\", metrics=[my_mae])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "337/363 [==========================>...] - ETA: 0s - loss: 1.3881 - my_mae: 0.8130Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3255 - my_mae: 0.7900 - val_loss: 0.5569 - val_my_mae: 0.4819\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4419 - my_mae: 0.4767 - val_loss: 0.4590 - val_my_mae: 0.4574\n",
      "162/162 [==============================] - 0s 580us/step - loss: 0.4164 - my_mae: 0.4640\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4164235293865204, 0.4639803469181061]"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))\n",
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can turn this off by creating the model with `dynamic=True` (or calling `super().__init__(dynamic=True, **kwargs)` in the model's constructor):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(dynamic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=my_mse, optimizer=\"nadam\", metrics=[my_mae])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not the custom code will be called at each iteration. Let's fit, validate and evaluate with tiny datasets to avoid getting too much output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.507259368896484, 2.0566811561584473]"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled[:64], y_train[:64], epochs=1,\n",
    "          validation_data=(X_valid_scaled[:64], y_valid[:64]), verbose=0)\n",
    "model.evaluate(X_test_scaled[:64], y_test[:64], verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can compile a model with `run_eagerly=True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=my_mse, optimizer=\"nadam\", metrics=[my_mae], run_eagerly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.507259368896484, 2.0566811561584473]"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled[:64], y_train[:64], epochs=1,\n",
    "          validation_data=(X_valid_scaled[:64], y_valid[:64]), verbose=0)\n",
    "model.evaluate(X_test_scaled[:64], y_test[:64], verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining custom optimizers is not very common, but in case you are one of the happy few who gets to write one, here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMomentumOptimizer(keras.optimizers.Optimizer):\n",
    "    def __init__(self, learning_rate=0.001, momentum=0.9, name=\"MyMomentumOptimizer\", **kwargs):\n",
    "        \"\"\"Call super().__init__() and use _set_hyper() to store hyperparameters\"\"\"\n",
    "        super().__init__(name, **kwargs)\n",
    "        self._set_hyper(\"learning_rate\", kwargs.get(\"lr\", learning_rate)) # handle lr=learning_rate\n",
    "        self._set_hyper(\"decay\", self._initial_decay) # \n",
    "        self._set_hyper(\"momentum\", momentum)\n",
    "    \n",
    "    def _create_slots(self, var_list):\n",
    "        \"\"\"For each model variable, create the optimizer variable associated with it.\n",
    "        TensorFlow calls these optimizer variables \"slots\".\n",
    "        For momentum optimization, we need one momentum slot per model variable.\n",
    "        \"\"\"\n",
    "        for var in var_list:\n",
    "            self.add_slot(var, \"momentum\")\n",
    "\n",
    "    @tf.function\n",
    "    def _resource_apply_dense(self, grad, var):\n",
    "        \"\"\"Update the slots and perform one optimization step for one model variable\n",
    "        \"\"\"\n",
    "        var_dtype = var.dtype.base_dtype\n",
    "        lr_t = self._decayed_lr(var_dtype) # handle learning rate decay\n",
    "        momentum_var = self.get_slot(var, \"momentum\")\n",
    "        momentum_hyper = self._get_hyper(\"momentum\", var_dtype)\n",
    "        momentum_var.assign(momentum_var * momentum_hyper - (1. - momentum_hyper)* grad)\n",
    "        var.assign_add(momentum_var * lr_t)\n",
    "\n",
    "    def _resource_apply_sparse(self, grad, var):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {\n",
    "            **base_config,\n",
    "            \"learning_rate\": self._serialize_hyperparameter(\"learning_rate\"),\n",
    "            \"decay\": self._serialize_hyperparameter(\"decay\"),\n",
    "            \"momentum\": self._serialize_hyperparameter(\"momentum\"),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "363/363 [==============================] - 0s 660us/step - loss: 3.8128\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 0s 653us/step - loss: 1.4877\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 0s 656us/step - loss: 0.9162\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 0s 665us/step - loss: 0.7587\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 0s 659us/step - loss: 0.7050\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8c05299a00>"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([keras.layers.Dense(1, input_shape=[8])])\n",
    "model.compile(loss=\"mse\", optimizer=MyMomentumOptimizer())\n",
    "model.fit(X_train_scaled, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. to 11.\n",
    "See Appendix A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Implement a custom layer that performs _Layer Normalization_\n",
    "_We will use this type of layer in Chapter 15 when using Recurrent Neural Networks._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a.\n",
    "_Exercise: The `build()` method should define two trainable weights *α* and *β*, both of shape `input_shape[-1:]` and data type `tf.float32`. *α* should be initialized with 1s, and *β* with 0s._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution: see below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b.\n",
    "_Exercise: The `call()` method should compute the mean_ μ _and standard deviation_ σ _of each instance's features. For this, you can use `tf.nn.moments(inputs, axes=-1, keepdims=True)`, which returns the mean μ and the variance σ<sup>2</sup> of all instances (compute the square root of the variance to get the standard deviation). Then the function should compute and return *α*⊗(*X* - μ)/(σ + ε) + *β*, where ⊗ represents itemwise multiplication (`*`) and ε is a smoothing term (small constant to avoid division by zero, e.g., 0.001)._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNormalization(keras.layers.Layer):\n",
    "    def __init__(self, eps=0.001, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.eps = eps\n",
    "\n",
    "    def build(self, batch_input_shape):\n",
    "        self.alpha = self.add_weight(\n",
    "            name=\"alpha\", shape=batch_input_shape[-1:],\n",
    "            initializer=\"ones\")\n",
    "        self.beta = self.add_weight(\n",
    "            name=\"beta\", shape=batch_input_shape[-1:],\n",
    "            initializer=\"zeros\")\n",
    "        super().build(batch_input_shape) # must be at the end\n",
    "\n",
    "    def call(self, X):\n",
    "        mean, variance = tf.nn.moments(X, axes=-1, keepdims=True)\n",
    "        return self.alpha * (X - mean) / (tf.sqrt(variance + self.eps)) + self.beta\n",
    "\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return batch_input_shape\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"eps\": self.eps}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that making _ε_ a hyperparameter (`eps`) was not compulsory. Also note that it's preferable to compute `tf.sqrt(variance + self.eps)` rather than `tf.sqrt(variance) + self.eps`. Indeed, the derivative of sqrt(z) is undefined when z=0, so training will bomb whenever the variance vector has at least one component equal to 0. Adding _ε_ within the square root guarantees that this will never happen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c.\n",
    "_Exercise: Ensure that your custom layer produces the same (or very nearly the same) output as the `keras.layers.LayerNormalization` layer._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create one instance of each class, apply them to some data (e.g., the training set), and ensure that the difference is negligeable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-28 18:11:34.768778: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8401\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=3.894674e-08>"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X_train.astype(np.float32)\n",
    "\n",
    "custom_layer_norm = LayerNormalization()\n",
    "keras_layer_norm = keras.layers.LayerNormalization()\n",
    "\n",
    "tf.reduce_mean(keras.losses.mean_absolute_error(\n",
    "    keras_layer_norm(X), custom_layer_norm(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yep, that's close enough. To be extra sure, let's make alpha and beta completely random and compare again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=1.7224725e-08>"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_alpha = np.random.rand(X.shape[-1])\n",
    "random_beta = np.random.rand(X.shape[-1])\n",
    "\n",
    "custom_layer_norm.set_weights([random_alpha, random_beta])\n",
    "keras_layer_norm.set_weights([random_alpha, random_beta])\n",
    "\n",
    "tf.reduce_mean(keras.losses.mean_absolute_error(\n",
    "    keras_layer_norm(X), custom_layer_norm(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still a negligeable difference! Our custom layer works fine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Train a model using a custom training loop to tackle the Fashion MNIST dataset\n",
    "_The Fashion MNIST dataset was introduced in Chapter 10._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a.\n",
    "_Exercise: Display the epoch, iteration, mean training loss, and mean accuracy over each epoch (updated at each iteration), as well as the validation loss and accuracy at the end of each epoch._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "X_train_full = X_train_full.astype(np.float32) / 255.\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test.astype(np.float32) / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "batch_size = 32\n",
    "n_steps = len(X_train) // batch_size\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "loss_fn = keras.losses.sparse_categorical_crossentropy\n",
    "mean_loss = keras.metrics.Mean()\n",
    "metrics = [keras.metrics.SparseCategoricalAccuracy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8054756eedc45acb92197fabeffc7f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "All epochs:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00d36ae31aee41629ad0eb27eeb42926",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6261acd0016e4bfc8a9748bad4bc0cdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "653eb59d01984a479751f4800271b42a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a70f4d4d4ee444c695b3b62c8c6dbcdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c77f30d2be448b99f94b4be8cd9b2a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with trange(1, n_epochs + 1, desc=\"All epochs\") as epochs:\n",
    "    for epoch in epochs:\n",
    "        with trange(1, n_steps + 1, desc=\"Epoch {}/{}\".format(epoch, n_epochs)) as steps:\n",
    "            for step in steps:\n",
    "                X_batch, y_batch = random_batch(X_train, y_train)\n",
    "                with tf.GradientTape() as tape:\n",
    "                    y_pred = model(X_batch)\n",
    "                    main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "                    loss = tf.add_n([main_loss] + model.losses)\n",
    "                gradients = tape.gradient(loss, model.trainable_variables)\n",
    "                optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "                for variable in model.variables:\n",
    "                    if variable.constraint is not None:\n",
    "                        variable.assign(variable.constraint(variable))                    \n",
    "                status = OrderedDict()\n",
    "                mean_loss(loss)\n",
    "                status[\"loss\"] = mean_loss.result().numpy()\n",
    "                for metric in metrics:\n",
    "                    metric(y_batch, y_pred)\n",
    "                    status[metric.name] = metric.result().numpy()\n",
    "                steps.set_postfix(status)\n",
    "            y_pred = model(X_valid)\n",
    "            status[\"val_loss\"] = np.mean(loss_fn(y_valid, y_pred))\n",
    "            status[\"val_accuracy\"] = np.mean(keras.metrics.sparse_categorical_accuracy(\n",
    "                tf.constant(y_valid, dtype=np.float32), y_pred))\n",
    "            steps.set_postfix(status)\n",
    "        for metric in [mean_loss] + metrics:\n",
    "            metric.reset_states()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b.\n",
    "_Exercise: Try using a different optimizer with a different learning rate for the upper layers and the lower layers._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_layers = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "])\n",
    "upper_layers = keras.models.Sequential([\n",
    "    keras.layers.Dense(10, activation=\"softmax\"),\n",
    "])\n",
    "model = keras.models.Sequential([\n",
    "    lower_layers, upper_layers\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_optimizer = keras.optimizers.SGD(learning_rate=1e-4)\n",
    "upper_optimizer = keras.optimizers.Nadam(learning_rate=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "batch_size = 32\n",
    "n_steps = len(X_train) // batch_size\n",
    "loss_fn = keras.losses.sparse_categorical_crossentropy\n",
    "mean_loss = keras.metrics.Mean()\n",
    "metrics = [keras.metrics.SparseCategoricalAccuracy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ef9943a19f2423dba9141b1eda4107e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "All epochs:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b258b83c76044cd6b9a676855c69f634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71113ea4bfad47c79c05959bbd26c05a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4af7098382fe4bfc8aff4a1b436ba497",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "855894b45ca14a8d85b60b8e8cc76fa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1f0df7dbc6041ee9f2a594d6c12f856",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with trange(1, n_epochs + 1, desc=\"All epochs\") as epochs:\n",
    "    for epoch in epochs:\n",
    "        with trange(1, n_steps + 1, desc=\"Epoch {}/{}\".format(epoch, n_epochs)) as steps:\n",
    "            for step in steps:\n",
    "                X_batch, y_batch = random_batch(X_train, y_train)\n",
    "                with tf.GradientTape(persistent=True) as tape:\n",
    "                    y_pred = model(X_batch)\n",
    "                    main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "                    loss = tf.add_n([main_loss] + model.losses)\n",
    "                for layers, optimizer in ((lower_layers, lower_optimizer),\n",
    "                                          (upper_layers, upper_optimizer)):\n",
    "                    gradients = tape.gradient(loss, layers.trainable_variables)\n",
    "                    optimizer.apply_gradients(zip(gradients, layers.trainable_variables))\n",
    "                del tape\n",
    "                for variable in model.variables:\n",
    "                    if variable.constraint is not None:\n",
    "                        variable.assign(variable.constraint(variable))                    \n",
    "                status = OrderedDict()\n",
    "                mean_loss(loss)\n",
    "                status[\"loss\"] = mean_loss.result().numpy()\n",
    "                for metric in metrics:\n",
    "                    metric(y_batch, y_pred)\n",
    "                    status[metric.name] = metric.result().numpy()\n",
    "                steps.set_postfix(status)\n",
    "            y_pred = model(X_valid)\n",
    "            status[\"val_loss\"] = np.mean(loss_fn(y_valid, y_pred))\n",
    "            status[\"val_accuracy\"] = np.mean(keras.metrics.sparse_categorical_accuracy(\n",
    "                tf.constant(y_valid, dtype=np.float32), y_pred))\n",
    "            steps.set_postfix(status)\n",
    "        for metric in [mean_loss] + metrics:\n",
    "            metric.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
